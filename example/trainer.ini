[Project]
name=LLM
version=1.0
user=garfield
pipeline=TokenizerLoader,ModelLoader,Trainer
#proxies={"http": "127.0.0.1:7890", "https": "127.0.0.1:7890"}

[Lora]
r=16
lora_alpha=32
target_modules=q_proj,v_proj
lora_dropout=0.05
bias=none,
task_type=CAUSAL_LM

[TokenizerLoader]
pretrained_model_name_or_path=THUDM/chatglm3-6b
use_fast=True
split_special_tokens=True
padding_side=right
device_map=auto
trust_remote_code=True


[ModelLoader]
pretrained_model_name_or_path=facebook/opt-1.3b


[TrainArgument]
per_device_train_batch_size=4
gradient_accumulation_steps=4
warmup_steps=100
max_steps=200
learning_rate=2e-4
fp16=True
logging_steps=25
output_dir=outputs


[DataCollator]


[Trainer]
model=model
args=TrainArgument
data_collator=data_collator,
callbacks=callbacks,




